{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow v1 기능만 사용 (v2 기능 강제 차단)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fold = 5\n",
    "\n",
    "# k-fold 학습/검증 데이터\n",
    "for i in range(Fold):\n",
    "    \n",
    "    path1 = './K_FoldData/Training_Fold%d'%(i+1)\n",
    "    path2 = './K_FoldData/Validation_Fold%d'%(i+1)\n",
    "    c1 = 'Training_Fold%d   = np.array(pd.read_csv(path1, sep=\",\", header=None))'%(i+1)\n",
    "    c2 = 'Validation_Fold%d = np.array(pd.read_csv(path2, sep=\",\", header=None))'%(i+1)\n",
    "    exec(c1)\n",
    "    exec(c2)\n",
    "\n",
    "# K-fold 학습/검증 레이블\n",
    "TrainingFold_Label   = np.array(pd.read_csv('./K_FoldData/TrainingFold_Label_forANN'  , sep=\",\", header=None))\n",
    "ValidationFold_Label = np.array(pd.read_csv('./K_FoldData/ValidationFold_Label_forANN', sep=\",\", header=None))\n",
    "    \n",
    "    \n",
    "# 전체 학습용 데이터\n",
    "Training_All       = np.array(pd.read_csv('./K_FoldData/Training_All', sep = \",\", header = None))\n",
    "Training_All_Label = np.array(pd.read_csv('./K_FoldData/Training_All_Label_forANN', sep = \",\", header = None))\n",
    "\n",
    "print(Training_Fold1.shape)\n",
    "print(Validation_Fold1.shape)\n",
    "print(TrainingFold_Label.shape)\n",
    "print(ValidationFold_Label.shape)\n",
    "print(Training_All.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN(Artificial Neural Network) hyperparameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate  = 0.0001\n",
    "noOfNeuron    = 20\n",
    "iteration     = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN의 구조(Architecture) 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, Training_Fold1.shape[1]])\n",
    "Y = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "# dropout (keep_prob) rate 0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# weights & bias for nn layers\n",
    "\n",
    "# Input Layer\n",
    "W1 = tf.Variable(tf.random_normal([Training_Fold1.shape[1], noOfNeuron]))\n",
    "b1 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# Hidden Layer 1\n",
    "W2 = tf.Variable(tf.random_normal([noOfNeuron, noOfNeuron]))\n",
    "b2 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "# Hidden Layer 2\n",
    "W3 = tf.Variable(tf.random_normal([noOfNeuron, noOfNeuron]))\n",
    "b3 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "# Output Layer\n",
    "W4 = tf.Variable(tf.random_normal([noOfNeuron, 2]))\n",
    "b4 = tf.Variable(tf.random_normal([2]))\n",
    "hypothesis = tf.matmul(L3, W4) + b4\n",
    "\n",
    "\n",
    "# define cost/loss &optimizer\n",
    "cost      = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(cost)\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN(Neural Network) 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = TrainingFold_Label\n",
    "Label_Val = ValidationFold_Label\n",
    "\n",
    "for i in range(Fold):\n",
    "    \n",
    "    s1= 'Data = Training_Fold%d'%(i+1)\n",
    "    s2= 'Data_Val = Validation_Fold%d'%(i+1)\n",
    "    exec(s1)\n",
    "    exec(s2)\n",
    "\n",
    "# train my model\n",
    "# initialize\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(1, iteration+1):\n",
    "    \n",
    "        c, _ = sess.run([cost, optimizer], feed_dict = {X : Data, Y: Label})\n",
    "        s2 = 'Validation_Acc_Fold%d = sess.run(accuracy, feed_dict={X : Data_Val, Y: Label_Val})'%(i+1)\n",
    "        exec(s2)\n",
    "\n",
    "Accuracy_sum = 0\n",
    "\n",
    "for j in range(Fold):\n",
    "    \n",
    "    s3 = 'Accuracy_sum += Validation_Acc_Fold%d'%(j+1)\n",
    "    exec(s3)\n",
    "    \n",
    "print('[Reslut of K-fold Cross Validation] \\n')\n",
    "print('Fold 1: {:.5f} \\nFold 2: {:.5f} \\nFold 3: {:.5f} \\nFold 4: {:.5f} \\nFold 5: {:.5f} \\n\\n * Average accuracy : {:.5f}'\n",
    "      .format(Validation_Acc_Fold1, Validation_Acc_Fold2, Validation_Acc_Fold3, Validation_Acc_Fold4, Validation_Acc_Fold5, Accuracy_sum/Fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 학습 데이터로 NN 학습 및 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = Training_All\n",
    "y_data = Training_All_Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train my model\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(1, iteration+1):\n",
    "    \n",
    "    c, _ = sess.run([cost, optimizer], feed_dict = {X : x_data, Y: y_data})\n",
    "    Acc = sess.run(accuracy, feed_dict={X : x_data, Y: y_data})\n",
    "   \n",
    "    if step % 1000 == 0:\n",
    "            \n",
    "        print('iteration {}'.format(step))    \n",
    "        print('   Validation Acc: {:.5f}'.format(Acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './MLmodels/ANN_model_tf1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN model 불러와서 진단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로우 그래프 초기화 (아무것도 작성안했을 시 실행 X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Graph 지울 때 사용\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, Training_Fold1.shape[1]])\n",
    "Y = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "# dropout (keep_prob) rate 0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# weights & bias for nn layers\n",
    "\n",
    "# Input Layer\n",
    "W1 = tf.Variable(tf.random_normal([Training_Fold1.shape[1], noOfNeuron]))\n",
    "b1 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "# Hidden Layer 1\n",
    "W2 = tf.Variable(tf.random_normal([noOfNeuron, noOfNeuron]))\n",
    "b2 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "# Hidden Layer 2\n",
    "W3 = tf.Variable(tf.random_normal([noOfNeuron, noOfNeuron]))\n",
    "b3 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "# Output Layer\n",
    "W4 = tf.Variable(tf.random_normal([noOfNeuron, 2]))\n",
    "b4 = tf.Variable(tf.random_normal([2]))\n",
    "hypothesis = tf.matmul(L3, W4) + b4\n",
    "\n",
    "\n",
    "# define cost/loss &optimizer\n",
    "cost      = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(cost)\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기 (그래프에 Variable w, b 불러옴)\n",
    "sess  = tf.Session()\n",
    "LoadedModel = tf.train.Saver()\n",
    "LoadedModel.restore(sess, './MLmodels/ANN_model_tf1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Fold):\n",
    "    \n",
    "    s1= 'Data = Training_Fold%d'%(i+1)\n",
    "    s2= 'Data_Val = Validation_Fold%d'%(i+1)\n",
    "    exec(s1)\n",
    "    exec(s2)\n",
    "\n",
    "    s3 = 'Validation_Acc_Fold%d = sess.run(accuracy, feed_dict={X : Data_Val, Y: Label_Val})'%(i+1)\n",
    "    exec(s3)\n",
    "\n",
    "Accuracy_sum = 0\n",
    "\n",
    "for j in range(Fold):\n",
    "    \n",
    "    s3 = 'Accuracy_sum += Validation_Acc_Fold%d'%(j+1)\n",
    "    exec(s3)\n",
    "\n",
    "print('[Performance of ANN(tf1) model] \\n')\n",
    "print('Fold 1: {:.5f} \\nFold 2: {:.5f} \\nFold 3: {:.5f} \\nFold 4: {:.5f} \\nFold 5: {:.5f} \\n\\n * Average accuracy : {:.5f}'\n",
    "      .format(Validation_Acc_Fold1, Validation_Acc_Fold2, Validation_Acc_Fold3, Validation_Acc_Fold4, Validation_Acc_Fold5, Accuracy_sum/Fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}