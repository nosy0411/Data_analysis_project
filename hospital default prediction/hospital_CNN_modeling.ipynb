{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598848523461",
   "display_name": "Python 3.6.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20-1학기 시스템 경영 종합 설계\n",
    "# 5조 인공 신경망을 이용한 병원 폐업 예측 모델링  \n",
    "\n",
    "# - 목차 -\n",
    "- 연구 목적\n",
    "- 데이터 로드\n",
    "- 데이터 전처리\n",
    "- 모델링 및 학습\n",
    "- 예측 및 평가\n",
    "\n",
    "# 연구 목적\n",
    "\n",
    "대출 상품의 심사 과정에서, 병원의 상환 기간 내 폐업 가능성을 예측해 대출 승인/반려 여부를 결정한다. 또한, 리스크에 따라 우대이율을 책정하기 위해 병원의 폐업 여부를 예측한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 301 entries, 0 to 300\nData columns (total 59 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   index               301 non-null    int64  \n 1   inst_id             301 non-null    int64  \n 2   OC                  301 non-null    object \n 3   sido                301 non-null    object \n 4   sgg                 301 non-null    int64  \n 5   openDate            301 non-null    int64  \n 6   bedCount            296 non-null    float64\n 7   instkind            300 non-null    object \n 8   revenue1            293 non-null    float64\n 9   salescost1          293 non-null    float64\n 10  sga1                293 non-null    float64\n 11  salary1             293 non-null    float64\n 12  noi1                293 non-null    float64\n 13  noe1                293 non-null    float64\n 14  interest1           293 non-null    float64\n 15  ctax1               293 non-null    float64\n 16  profit1             293 non-null    float64\n 17  liquidAsset1        293 non-null    float64\n 18  quickAsset1         293 non-null    float64\n 19  receivableS1        293 non-null    float64\n 20  inventoryAsset1     293 non-null    float64\n 21  nonCAsset1          293 non-null    float64\n 22  tanAsset1           293 non-null    float64\n 23  OnonCAsset1         293 non-null    float64\n 24  receivableL1        293 non-null    float64\n 25  debt1               293 non-null    float64\n 26  liquidLiabilities1  293 non-null    float64\n 27  shortLoan1          293 non-null    float64\n 28  NCLiabilities1      293 non-null    float64\n 29  longLoan1           293 non-null    float64\n 30  netAsset1           293 non-null    float64\n 31  surplus1            293 non-null    float64\n 32  revenue2            293 non-null    float64\n 33  salescost2          293 non-null    float64\n 34  sga2                293 non-null    float64\n 35  salary2             293 non-null    float64\n 36  noi2                293 non-null    float64\n 37  noe2                293 non-null    float64\n 38  interest2           293 non-null    float64\n 39  ctax2               293 non-null    float64\n 40  profit2             293 non-null    float64\n 41  liquidAsset2        293 non-null    float64\n 42  quickAsset2         293 non-null    float64\n 43  receivableS2        293 non-null    float64\n 44  inventoryAsset2     293 non-null    float64\n 45  nonCAsset2          293 non-null    float64\n 46  tanAsset2           293 non-null    float64\n 47  OnonCAsset2         293 non-null    float64\n 48  receivableL2        293 non-null    float64\n 49  debt2               293 non-null    float64\n 50  liquidLiabilities2  293 non-null    float64\n 51  shortLoan2          293 non-null    float64\n 52  NCLiabilities2      293 non-null    float64\n 53  longLoan2           293 non-null    float64\n 54  netAsset2           293 non-null    float64\n 55  surplus2            293 non-null    float64\n 56  employee1           291 non-null    float64\n 57  employee2           288 non-null    float64\n 58  ownerChange         289 non-null    object \ndtypes: float64(51), int64(4), object(4)\nmemory usage: 138.9+ KB\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('./data/train.csv').reset_index()\n",
    "test_data = pd.read_csv('./data/test.csv').reset_index()\n",
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "## 결측치\n",
    "* 학습 데이터 중 8개의 인스턴스에서 대부분의 값이 NaN이므로 8개 행을 삭제하였다. \n",
    "* 여러 값에서 결측치(NaN, 0)가 발생하여 평균으로 대체하였다.\n",
    "* employee 정보는 임금(salary)를 인당 평균 임금으로 나누어 추정하였다. \n",
    "* OwnerChange는 NaN일 때 unknown으로 변환한 후 same과 change의 중간값을 부여하였다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8개의 NA행 삭제  \n",
    "missing_idx_revenue1 = np.where(np.isnan(train_data['revenue1']))[0]\n",
    "X_train_dropna = train_data.drop(missing_idx_revenue1).reset_index()\n",
    "\n",
    "# ownerChange\n",
    "missing_idx_ownerChange = np.where(pd.isnull(X_train_dropna['ownerChange']))\n",
    "for idx in missing_idx_ownerChange:\n",
    "    X_train_dropna['ownerChange'].loc[idx] = 'unknown' \n",
    "ownerChange_map = {'same':0, 'change':1, 'unknown': 0.5}\n",
    "X_train_dropna['ownerChange'] = X_train_dropna['ownerChange'].apply(ownerChange_map.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employee estimation\n",
    "missing_idx_employee1 = np.where(np.isnan(X_train_dropna['employee1']))[0]\n",
    "missing_idx_employee2 = np.where(np.isnan(X_train_dropna['employee2']))[0]\n",
    "missing_idx_employee_union = sorted(list(set(missing_idx_employee1).union(set(missing_idx_employee2))))\n",
    "missing_idx_employee_intersection = sorted(list(set(missing_idx_employee1).intersection(set(missing_idx_employee2))))\n",
    "for idx in missing_idx_employee_union:\n",
    "    if idx in missing_idx_employee_intersection:\n",
    "        pass\n",
    "    elif idx in missing_idx_employee1:\n",
    "        X_train_dropna['employee1'].loc[idx] = X_train_dropna['employee2'].loc[idx]\n",
    "    else:\n",
    "        X_train_dropna['employee2'].loc[idx] = X_train_dropna['employee1'].loc[idx]\n",
    "X_train_salary = X_train_dropna.drop(missing_idx_employee_intersection)\n",
    "avg_salary = (np.sum(X_train_salary['salary1'], axis=0)/np.sum(X_train_salary['employee1'])+\n",
    "              np.sum(X_train_salary['salary2'], axis=0)/np.sum(X_train_salary['employee2']))/2\n",
    "for idx in missing_idx_employee_intersection:\n",
    "    salary1 = X_train_dropna['salary1'].loc[idx]\n",
    "    salary2 = X_train_dropna['salary2'].loc[idx]\n",
    "    employee1 = int(salary1/avg_salary)\n",
    "    employee2 = int(salary2/avg_salary)\n",
    "    X_train_dropna['employee1'].loc[idx] = employee1\n",
    "    X_train_dropna['employee2'].loc[idx] = employee2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나머지 평균으로 결측치 예측\n",
    "X_train_dropna = X_train_dropna.replace(0, np.NaN)\n",
    "X_train_dropna_imputed = X_train_dropna.fillna(X_train_dropna.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling and Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "y_train = X_train_dropna['OC']\n",
    "# 미사용 column 삭제\n",
    "X_train_dropna_imputed = X_train_dropna_imputed.drop(['OC','sido','inst_id','level_0','index','sgg',\n",
    "                         'receivableL1','receivableL2'], axis=1)\n",
    "\n",
    "# category형 변수 one-hot encoding\n",
    "X_train = pd.get_dummies(X_train_dropna_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature별 standard scaling\n",
    "feature_mean = []\n",
    "feature_std = []\n",
    "for column in X_train.columns[:50]:\n",
    "    mean = X_train[column].mean()\n",
    "    std = X_train[column].std()\n",
    "    X_train[column] -= mean\n",
    "    X_train[column] /= std\n",
    "    feature_mean.append(mean)\n",
    "    feature_std.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# owner change는 same:0 change:1 unknown:0.5 부여\n",
    "X_train['ownerChange'] = X_train['ownerChange'].replace(X_train['ownerChange'][0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "open_map = {'open':1, ' close':0}\n",
    "y_train = y_train.apply(open_map.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ownerChange\n",
    "missing_idx_ownerChange = np.where(pd.isnull(test_data['ownerChange']))\n",
    "for idx in missing_idx_ownerChange:\n",
    "    test_data['ownerChange'].loc[idx] = 'unknown' \n",
    "test_data['ownerChange'] = test_data['ownerChange'].apply(ownerChange_map.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employee estimation\n",
    "missing_idx_employee1 = np.where(pd.isnull(test_data['employee1']))[0]\n",
    "missing_idx_employee2 = np.where(pd.isnull(test_data['employee2']))[0]\n",
    "missing_idx_employee_union = sorted(list(set(missing_idx_employee1).union(set(missing_idx_employee2))))\n",
    "missing_idx_employee_intersection = sorted(list(set(missing_idx_employee1).intersection(set(missing_idx_employee2))))\n",
    "for idx in missing_idx_employee_union:\n",
    "    if idx in missing_idx_employee_intersection:\n",
    "        pass\n",
    "    elif idx in missing_idx_employee1:\n",
    "        test_data['employee1'].loc[idx] = test_data['employee2'].loc[idx]\n",
    "    else:\n",
    "        test_data['employee2'].loc[idx] = test_data['employee1'].loc[idx]\n",
    "for idx in missing_idx_employee_intersection:\n",
    "    salary1 = test_data['salary1'].loc[idx]\n",
    "    salary2 = test_data['salary2'].loc[idx]\n",
    "    employee1 = int(salary1/avg_salary)\n",
    "    employee2 = int(salary2/avg_salary)\n",
    "    test_data['employee1'].loc[idx] = employee1\n",
    "    test_data['employee2'].loc[idx] = employee2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나머지 평균으로 결측치 예측\n",
    "test_data = test_data.replace(0, np.NaN)\n",
    "test_data_imputed = test_data.fillna(X_train_dropna.mean())\n",
    "\n",
    "test_data_imputed.employee1 = test_data_imputed.employee1.astype('str').str.replace(\",\", \"\").astype('float')\n",
    "test_data_imputed.employee2 = test_data_imputed.employee2.astype('str').str.replace(\",\", \"\").astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_imputed = test_data_imputed.drop(['OC','sido','inst_id','index','sgg',\n",
    "                         'receivableL1','receivableL2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category형 변수 one-hot encoding\n",
    "X_test = pd.get_dummies(test_data_imputed)\n",
    "X_test['instkind_dental_clinic'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature별 standard scaling\n",
    "for column_num in range(50):\n",
    "    mean = feature_mean[column_num]\n",
    "    std = feature_std[column_num]\n",
    "    X_test[X_test.columns[column_num]] -= mean\n",
    "    X_test[X_test.columns[column_num]] /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링 및 학습 (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train accuracy: 0.9436988543371522\ncross validation accuracy mean: 0.9453535943892462\n"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "RANDOM = 7777\n",
    "clf = MLPClassifier(hidden_layer_sizes=(30,30,30), max_iter=5000, early_stopping=True, random_state=RANDOM)\n",
    "\n",
    "cv = cross_validate(clf, X_train, y_train, cv=5,return_train_score=True)\n",
    "\n",
    "print('train accuracy:',np.mean(cv['train_score']))\n",
    "print('cross validation accuracy mean:',np.mean(cv['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}