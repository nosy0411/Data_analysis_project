이번에 스마트폰 데이터를 이용한 HAR 시스템이라는 주제를 마무리 지었고 어떻게 연구를 했는지 발표하도록 하겠습니다.
1번과 2번에 대한 내용은 5.19일에 했던 중간발표 내용이고 오늘은 3번 탐색적 자료 분석, 4번 모델 생성 및 검증, 5번 결론 및 개선점 위주로
중간발표 이후에 했던 활동들에 대해 발표하도록 하겠습니다.

먼저 중간 발표 이전에 대한 내용을 간단히 리뷰하자면 이 연구는 스마트폰에서 얻어진 센서데이터를 분석하여 인간의 활동을 인식하는 것이 목적이었고
6개의 활동을 인식하고자 하는 다중 클래스 분류 문제였습니다. 가속도 센서와 자이로 센서에서 수집된 raw data를 7:3으로 train과 test로 나눴고 
시간에 대한 센서 데이터를 고속 퓨리에 변환을 이용하여 주파수 신호 데이터로 변환하고 필터링 과정을 거쳐 데이터를 어떻게 전처리 하였는지 알아보았습니다.
그리고 전처리된 데이터를 분석이 쉽게 csv 형식으로 Train과 Test 파일로 병합하는 것까지 중간발표에서 알아보았습니다.
다음 내용이 중간발표 이후 계획에 대한 내용이었고 큰 변화 없이 계획을 수행하였습니다. 종강 후 7.5일까지 진행하였고 기간동안 했던 내용을 
발표하도록 하겠습니다.

먼저 데이터의 특성을 알기 위해서 탐색적 자료 분석을 하였습니다. 병합된 파일인 Train과 Test파일에 결측치와 중복값이 없음을 확인했고
다중 클래스 분류 문제의 타겟이 데이터에 어떻게 분포되어 있는지 히스토그램을 통해 파악했습니다. 
타겟 분포가 균형적인지 불균형적인지에 따라 모델과 평가지표를 선정하는 방식을 달리해야 하기 때문에 위 분석을 수행했고 비교적 고른 분포를 보임을
확인할 수 있었습니다. 

그리고 데이터 분포 특성을 보기 위해서 distribution plot을 그려보았습니다. x축 데이터는 스마트폰 가속도 크기의 평균을 나타내는 feature인데 
6가지 활동이 앉기, 서있기, 눕기와 같은 3가지 정적활동과 걷기, 아래로 걷기, 위로 걷기와 같은 동적활동으로 크게 나눠지는데 그 특성을 잘 보여줄 수 있을 것 
같아서 선택하였습니다. 파이썬의 seaborn 패키지의 displot을 이용해서 시각화 해본 결과가 다음과 같이 -0.5를 기준으로 3가지씩 나눠짐을 확인할 수 있었습니다.
그 결과를 3가지씩 묶어서 따로 본 그림이고  tBodyAccMag-mean()뿐만아니라 중력과 x축, y축 사이의 각도 같은 feature도 Boxplot을 통해 확인해본 결과
특정 값을 기준으로 분포가 구분됨을 알 수 있었습니다. 그래서 EDA를 통해서 특정 feature가 분류에 유의미한 영향을 줌을 어느정도 확인할 수 있었습니다.
다음은 데이터의 차원을 축소하는 과정을 진행하였습니다. 현재 561개의 피쳐가 있기 때문에 후에 tsne를 사용해서 시각화 하기 위해서는 차원 축소를
하지않으면 너무 시간이 많이 걸려서 PCA를 통해 차원을 축소하는 과정을 진행하였습니다.
PCA의 원리는 데이터에 가장 가까운 초평면을 구한 다음 데이터를 초평면에 투영시켜는 방식입니다. 그림처럼 2차원 데이터의 경우에는

초평면이 선이 되고 	그 선에 투영이 되는데 투영된 데이터의 분산이 가장 크게 투영되는 축을 수학적으로 선형결합을 이용하여 구합니다. 
그리고 다른축을 선정할때는 마찬가지로 변환된 데이터의 분산이 가장 크게 되도록 한 상태에서 
기존 축과 상관관계가 없도록 즉 수직이 되도록 선정을 합니다. 이렇게 함으로써 데이터 분포의 특성은 크게 변하지 않으면서 분석 속도를 증가시킬 수 있었습니다.
이 때 축소를 하는 방식으로 축의 개수를 선정하는 방식과 원 데이터의 분산을 얼마나 설명하는지 정해놓고 하는 방식 2가지가 있는데
저는 원데이터의 90퍼의 분산을 설명할 수 있도록 하였습니다. 이렇게 하면 90퍼를 설명할 수 있는 축의 갯수를 선정하게 됩니다.

다음과 같이 축소된 데이터로 tsne 시각화를 진행하였습니다.
tsne 방식에 대해 간단하게 얘기하고 넘어가자면 다음 그림이 swiss roll이란 그림인데 하나의 초평면으로 투영해서 축소하는 방식에 문제가 있음을 알 수 있습니다.
그래서 tsne는 manifold learning이라는 방식을 사용하는데 특정 위상공간에 데이터가 분포해 있을 것이라는 가정으로 부터 출발하게 됩니다.
swiss roll의 경우에 다음과 같이 manifold를 구성할 수 있겠고 이런 manifold라는게 경험적으로 관찰된다고 합니다. 이건 수학적으로 엄밀한 방법이 아니고
어떤 원리를 통해 결과물이 나왔는지 정확히 파악하기 힘들다는 단점이 있습니다. 그렇지만 시각화에 널리 쓰이기 때문에 저도 사용해봤고 다음과 같이
활동별로 군집을 이룸을 알 수 있었습니다.

지금까지 과정을 통해 활동이 특정 기준으로 구분되고 시각적으로 군집을 이룸을 확인할 수 있었습니다. 그래서 계획에서 정한 
활동들을 분류해주는 모델을 선정하였고 교차검증을 통해 가장 데이터를 잘 설명하는 모델의 최적 모수 hyperparameter를 확인하고 
최적모수를 가진 모델로 테스트하여 평가지표 accuracy값을 계산하였습니다. 그리고 마지막으로 confusion matrix를 이용해 각 활동별 인식 결과를
시각화 하였습니다. 먼저 가장 기본적인 로지스틱 회귀분석을 실시하였습니다. 이 식이 예측값을 구하는 로지스틱 회귀분석 식인데

이 예측 최적 모델을 구하기 위해서 cost function 함수가 최소가 되는 가중치 w값을 찾아주게 됩니다. 로지스틱 회귀분석에서는 cross entorpy라는
식을 cost function으로 사용하게 되고 여기에 과적합을 방지하게 위해 다음과 같이 리지와 라쏘라고 불리는 L2 와 L1 항을 추가하여 regularization을
수행하게 됩니다.

그래서 이 L2, L1과 이 regularization 강도의 역수를 나타내는 c값을 hyperparameter라고 두고 여러 하이퍼파라미터들을 가진 로지스틱 회귀분석 모델을
생성하였습니다. 그리고 교차검증 구간을 5개로 해서 RandomizedSearchCV를 수행하였습니다.
그래서 최종적으로 train 데이터에서 최적 모수를 가진 로지스틱 모델을 test data에서 테스트 했더니 정확도가 96퍼가 나왔습니다.
이 때 이 최적 모델은 c=10, L2 regularization 하이퍼파라미터 값을 가졌고 이 모델이 train data를 94퍼 정확도로 분류함을 확인하였습니다.
그리고 다음과 같이 결과를 confusion matrix로 시각화 해보았습니다. 그림상으로도 대각선 방향으로 큰 오류 없이 인식이 잘 되었음을 확인할 수 있습니다.
다음은 서포트 벡터 머신입니다. 서포트 벡터 머신은 데이터를 분류하기 위한 초평면을 찾기 위한 방법 중 하나입니다.
간단하게 원리는 초평면과 데이터 사이의 거리인 마진이 가장 큰 초평면을 구하는 모델입니다. 수학적인 공식은 다음과 같이 hard와 soft 2가지 방식으로 나눠집니다.
그리고 linear 방식과 kernelized 방식이 있습니다. 일단 두 방식 모두 hyperparameter C가 있는데  그림과 같이 c가 클수록 overfitting 경향이 커지고 
작을수록 underfitting 경향이 커집니다. 이제 linear 방식의 단점으로는 그림과 같이 2차원인 저차원의 경우 초평면에 한계가 있어서 차원을 다음과 같이 3차원으로

늘려야 효과가 있음을 알 수 있는데 이렇게 수학적으로 차원을 늘리는 효과를 주는 방식이 kernelized SVM 입니다.
Kernelized SVM은 그림과 같이 비선형의 경계를 가진 데이터도 여기 나온 파이라는 특정 커널함수를 사용하여 고차원 공간으로 매핑시키면 
초평면을 생성할 수 있게 됩니다. 이걸 Kernel Trick이라고 하는데 여기서 사용하는 커널 함수중 가장 많이 쓰이는게 다음 과 같은 감마 항을 가진 지수식인
RBF 커널입니다. scikit-learn에서 KernelizedSVM을 적용할 때 디폴트 값으로 되어있습니다.
그래서 Kernelized SVM은 Linear SVM과 다르게 하이퍼파라미터가 c이외에도 kernel 함수와 감마값을 가짐을 확인할 수 있습니다.
지금까지 Linear SVM과 Kernelized SVM의 원리에 대해 간단하게 알아보았고 Linear SVM 모델을 전의 로지스틱 회귀분석 할때와 같은 방식으로 진행하였습니다.
교차검증을 통과한 최종 모델을 테스트 데이터에 적용해보니 97퍼의 정확도가 나왔고 변하는 hyperparameter는 c하나만 두고 
나머지는 scikit-learn의 디폴트 값을 사용하였습니다. 여기서 짚고 넘어가야할게 이 연구는 다중 클래스 분류 문제기 때문에 
이진 클래스 문제로 변환하여 구하는 방식을 취하는데 크게 one vs one 방식과 one vs rest 방식이 있는데 여기서는 후자를 사용했습니다. 
ovr방법은 각 클래스에 표본이 속하는지 속하지 않는지만 이진 판별하면 되서 ovo에 비해 판별하는 양이 더 적다는 장점이 있습니다.
분석을 한 결과 다음과 같이 hyperparameter c가 1이 나왔고 최적 모델은 train데이터를 94퍼 설명함을 확인하였습니다.
그리고 마찬가지로 분류결과를 시각화하였고 큰 오류 없이 분류함을 그림상으로도 확인하였습니다.

Kernelized SVM은 앞서 언급했듯이 c와 gamma의 2개의 파라미터가 있어 이를 변수로 두었고 분석을 다음과 같이 진행하였습니다. 최종 테스트는 94퍼센트가 나왔습니다.
분석을 한 결과 다음과 같이 hyperparameter c가 8이 gamma가 0.125가 나왔고 최적 모델은 train데이터를 90퍼 설명함을 확인하였습니다.
다음은 의사결정나무 모델입니다. 로지스틱 회귀분석과 마찬가지로 분류에 널리 쓰이는 모델이고 다른점은 트리 기반으로 if else문을 이용해서 분류하는 원리입니다.

트리로 분류할때 Impurity를 가장 적게하는 방향으로 분류하는데 이 임퓨리티를 계산하는 기준으로 다음과 같은 3가지 방식을 사용합니다.
앞의 방식과 같이 파이썬 사이킷런을 이용하여 디시전 트리 분석을 수행하였습니다. 하이퍼 파라미터는 트리의 최고 깊이를 제한하는 max depth로 두고 
같은 방식으로 교차검증 구간을 5개로 해서 진행하였습니다. 최종 테스트는 87퍼가 나왔습니다.
임퓨리티 기준식은 사이킷런 기본 값인 지니를 사용하였고 그 이외에도 트리를 만들기 전에 가지치는 pre pruning, 트리를 만들고 가지치는 post pruning과 같이

오버피팅을 방지하기 위한 다양한 하이퍼파라미터들이 있는데 분석 속도상의 이유로 반영하지 못했습니다.
분석을 한 결과 다음과 같이 hyperparameter max_depth가 8이 나왔고 최적 모델은 train데이터를 85퍼 설명함을 확인하였습니다.
그리고 마찬가지로 분류결과를 시각화하였고 큰 오류 없이 분류함을 그림상으로도 확인하였습니다.

마지막 머신러닝 분석 모델로 랜덤 포레스트를 선정하였습니다. 랜덤 포레스트는 분류에 사용되는 모델로 과적합 되기 쉬운 트리 모델을 앙상블 즉 여러 개 합쳐서
새로운 모델을 생성하는 원리입니다. 각각의 트리모델은 bagging이라 불리는 복원추출을 적용하여 약간씩 다른 데이터를 이용해 생성되게 됩니다.

그리고 각 노드에서 feature수를 랜덤으로 선택하여 분류를 진행하게 됩니다.
랜덤 포레스트에서 트리의 수를 나타내는 n_estimators와 트리의 최고 깊이를 제한하는 max_depth를 hyperparameter로 두고 
교차검증 구간을 5개로 하여 교차검증을 수행하였습니다. 최종 테스트는 92퍼가 나왔습니다. 

전 슬라이드에서 말했다시피 각 노드에 feature 수를 랜덤으로 선택하는 기준이 되는 hyperparameter가 max_features라고 있는데 
속도상의 이유로 디폴트 값을 사용하였습니다. max_features가 클수록 forest에 있는 tree model 서로 비슷해지는 효과가 있습니다.
사이킷런에서 디폴트 값은 피쳐수의 루트값을 사용하게 됩니다.vlcu
분석을 한 결과 다음과 같이 hyperparameter 트리 갯수가 60개 max_depth가 8이 나왔고 최적 모델은 train데이터를 92퍼 설명함을 확인하였습니다.
그리고 마찬가지로 분류결과를 시각화하였습니다.

다음은 결론입니다. 지금까지 수행한 총 5개의 머신러닝 모델의 정확도를 표로 정리하였습니다. 결과의 정확도 순으로 초평면을 이용한 분류 모델이 
트리 기반 분류 모델보다 좋은 성능을 냄을 알 수 있습니다. 그리고  단순한 logistic보다는 조금 수학적으로 더 정교한 Linear SVM, 
Decision Tree 보다는 더 정교한 Random Forest 가 정확도가 더 높음을 알 수 있었습니다. 

다음은 향후 개선점에 대한 내용입니다. 앞에서 언급했듯이 컴퓨터 자원상, 시간상 적용하지 못했던 각 모델의 hyperparameter가 있는데 
이 하이퍼파라미터의 종류와 수를 다양하게 두어 좀 더 좋은 최적 모델을 설정하도록 개선해 볼 수 있습니다. 
그리고 Gradient boosting machine, XGBoost와 같이 데이터 분석에서 높은 정확도 값과 속도를 보여주는 분류모델이라고 
알려져 있는 모델들을 적용해 볼 수 있습니다. 그리고 지금까지의 분석은 실험자 총 30명의 특성을 반영하지 않았는데
실제로 tsne를 통해 분석해본 결과 같은 활동이더라도 사람에 따라 다른 군집으로 시각화 됨을 확인하였었습니다. 사람의 특성을 반영한 인식모델을 선정한다면
좀 더 정확한 분류를 할 수 있을 것입니다. 마지막으로 분석에 사용한 데이터가 직접 수집하고 전처리한 데이터가 아니기 때문에 방식에 대한 검증을 하지 못했습니다.
가능하다면 직접 스마트폰을 이용해서 데이터를 수집하고 전처리단에 다양한 방식을 적용시켜 개선점을 파악할 수 있을 것입니다.

지금까지가 제가 준비한 내용입니다. 감사합니다.

 







































 